require('dotenv').config({ path: require('path').resolve(__dirname, '../.env.local') })
const { createClient } = require('@sanity/client')
const fs = require('fs')

const client = createClient({
  projectId: process.env.NEXT_PUBLIC_SANITY_PROJECT_ID || '72m8vhy2',
  dataset: process.env.NEXT_PUBLIC_SANITY_DATASET || 'production',
  apiVersion: '2024-01-01',
  token: process.env.SANITY_API_TOKEN,
  useCdn: false
})

async function removeDuplicates() {
  const line = '='.repeat(60)
  console.log(line)
  console.log('ğŸ” é‡è¤‡è¨˜äº‹ã®å‰Šé™¤')
  console.log(line)
  console.log()

  const posts = await client.fetch(`*[_type == 'post'] {
    _id,
    title,
    'slug': slug.current,
    publishedAt,
    _createdAt,
    _updatedAt
  } | order(title asc)`)

  // ã‚¿ã‚¤ãƒˆãƒ«ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
  const titleGroups = new Map()
  for (const post of posts) {
    if (!titleGroups.has(post.title)) {
      titleGroups.set(post.title, [])
    }
    titleGroups.get(post.title).push(post)
  }

  // é‡è¤‡ãŒã‚ã‚‹ã‚°ãƒ«ãƒ¼ãƒ—ã‚’æŠ½å‡º
  const duplicateGroups = Array.from(titleGroups.entries())
    .filter(([_, posts]) => posts.length > 1)

  console.log(`é‡è¤‡è¨˜äº‹ã‚°ãƒ«ãƒ¼ãƒ—: ${duplicateGroups.length}ä»¶`)
  console.log(`ç·é‡è¤‡è¨˜äº‹æ•°: ${duplicateGroups.reduce((sum, [_, posts]) => sum + posts.length, 0)}ä»¶`)
  console.log()

  const toDelete = []
  const toKeep = []

  for (const [title, duplicatePosts] of duplicateGroups) {
    // ä½œæˆæ—¥ã§ä¸¦ã³æ›¿ãˆï¼ˆæ–°ã—ã„é †ï¼‰
    const sorted = duplicatePosts.sort((a, b) =>
      new Date(b._createdAt) - new Date(a._createdAt)
    )

    const newest = sorted[0]
    const oldest = sorted.slice(1)

    console.log('ğŸ“„ ' + title)
    console.log('   ä¿æŒ: ' + newest.slug + ' (ä½œæˆ: ' + newest._createdAt.substring(0, 10) + ')')

    for (const old of oldest) {
      console.log('   å‰Šé™¤: ' + old.slug + ' (ä½œæˆ: ' + old._createdAt.substring(0, 10) + ')')
      toDelete.push(old)
    }
    console.log()

    toKeep.push(newest)
  }

  console.log(line)
  console.log('ğŸ“Š å®Ÿè¡Œã‚µãƒãƒªãƒ¼')
  console.log(line)
  console.log(`ä¿æŒã™ã‚‹è¨˜äº‹: ${toKeep.length}ä»¶`)
  console.log(`å‰Šé™¤ã™ã‚‹è¨˜äº‹: ${toDelete.length}ä»¶`)
  console.log()

  // ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
  const reportPath = require('path').resolve(__dirname, '../internal-links-analysis/duplicate-posts-report.json')
  fs.writeFileSync(reportPath, JSON.stringify({
    toDelete: toDelete.map(p => ({
      _id: p._id,
      title: p.title,
      slug: p.slug,
      createdAt: p._createdAt,
      publishedAt: p.publishedAt
    })),
    toKeep: toKeep.map(p => ({
      _id: p._id,
      title: p.title,
      slug: p.slug,
      createdAt: p._createdAt,
      publishedAt: p.publishedAt
    }))
  }, null, 2))

  console.log(`ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: ${reportPath}`)
  console.log()
  console.log('âš ï¸  å®Ÿéš›ã«å‰Šé™¤ã™ã‚‹ã«ã¯ --execute ãƒ•ãƒ©ã‚°ã‚’ä»˜ã‘ã¦ãã ã•ã„')
  console.log('   node scripts/remove-duplicate-posts.js --execute')
  console.log()

  // --execute ãƒ•ãƒ©ã‚°ãŒã‚ã‚‹å ´åˆã®ã¿å‰Šé™¤å®Ÿè¡Œ
  if (process.argv.includes('--execute')) {
    console.log(line)
    console.log('ğŸ—‘ï¸  å‰Šé™¤ã‚’å®Ÿè¡Œä¸­...')
    console.log(line)
    console.log()

    let deletedCount = 0

    for (const post of toDelete) {
      try {
        await client.delete(post._id)
        console.log('âœ… å‰Šé™¤: ' + post.title + ' (' + post.slug + ')')
        deletedCount++
      } catch (error) {
        console.error('âŒ ã‚¨ãƒ©ãƒ¼: ' + post.title)
        console.error('   ' + error.message)
      }
    }

    console.log()
    console.log(line)
    console.log('âœ¨ å‰Šé™¤å®Œäº†')
    console.log(line)
    console.log(`å‰Šé™¤æˆåŠŸ: ${deletedCount}/${toDelete.length}ä»¶`)
    console.log()
  }
}

removeDuplicates().catch(console.error)
