#!/usr/bin/env python3
"""
SEOãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

GSCã¨GA4ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ„ã¿åˆã‚ã›ã¦ã€SEOåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚
- ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸åˆ†æ
- ã‚¯ã‚¨ãƒªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
- ãƒ‡ãƒã‚¤ã‚¹åˆ¥åˆ†æ
- æ”¹å–„ãƒã‚¤ãƒ³ãƒˆææ¡ˆ
"""

import os
import sys
from datetime import date
import pandas as pd

def analyze_top_pages(gsc_df, ga4_df):
    """ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸åˆ†æ"""
    print("\nğŸ“„ ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸åˆ†æ")

    # GSC: ãƒšãƒ¼ã‚¸åˆ¥é›†è¨ˆ
    gsc_pages = gsc_df.groupby("page").agg({
        "clicks": "sum",
        "impressions": "sum",
        "ctr": "mean",
        "position": "mean",
    }).reset_index()

    # GA4: ãƒšãƒ¼ã‚¸åˆ¥é›†è¨ˆ
    ga4_pages = ga4_df.groupby("pagePath").agg({
        "sessions": "sum",
        "totalUsers": "sum",
        "engagementRate": "mean",
    }).reset_index()

    # ãƒãƒ¼ã‚¸ï¼ˆãƒšãƒ¼ã‚¸ãƒ‘ã‚¹ãŒå®Œå…¨ä¸€è‡´ã™ã‚‹å ´åˆã®ã¿ï¼‰
    merged = pd.merge(
        gsc_pages,
        ga4_pages,
        left_on="page",
        right_on="pagePath",
        how="left"
    )

    # ãƒˆãƒƒãƒ—10ãƒšãƒ¼ã‚¸ï¼ˆã‚¯ãƒªãƒƒã‚¯æ•°é †ï¼‰
    top_pages = merged.nlargest(10, "clicks")

    report = []
    report.append("\n### ãƒˆãƒƒãƒ—10ãƒšãƒ¼ã‚¸ï¼ˆã‚¯ãƒªãƒƒã‚¯æ•°é †ï¼‰\n")
    report.append("| ãƒšãƒ¼ã‚¸ | ã‚¯ãƒªãƒƒã‚¯ | è¡¨ç¤ºå›æ•° | CTR | æ²è¼‰é †ä½ | ã‚»ãƒƒã‚·ãƒ§ãƒ³ |")
    report.append("|--------|---------|---------|-----|---------|-----------|")

    for _, row in top_pages.iterrows():
        page = row["page"].replace("https://prorenata.jp", "")[:50]
        clicks = int(row["clicks"])
        impressions = int(row["impressions"])
        ctr = row["ctr"] * 100
        position = row["position"]
        sessions = int(row["sessions"]) if pd.notna(row["sessions"]) else 0

        report.append(
            f"| {page} | {clicks:,} | {impressions:,} | {ctr:.2f}% | {position:.1f} | {sessions:,} |"
        )

    return "\n".join(report)

def analyze_queries(gsc_df):
    """æ¤œç´¢ã‚¯ã‚¨ãƒªåˆ†æ"""
    print("\nğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒªåˆ†æ")

    # ã‚¯ã‚¨ãƒªåˆ¥é›†è¨ˆ
    queries = gsc_df.groupby("query").agg({
        "clicks": "sum",
        "impressions": "sum",
        "ctr": "mean",
        "position": "mean",
    }).reset_index()

    # ãƒˆãƒƒãƒ—20ã‚¯ã‚¨ãƒªï¼ˆã‚¯ãƒªãƒƒã‚¯æ•°é †ï¼‰
    top_queries = queries.nlargest(20, "clicks")

    report = []
    report.append("\n### ãƒˆãƒƒãƒ—20æ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆã‚¯ãƒªãƒƒã‚¯æ•°é †ï¼‰\n")
    report.append("| æ¤œç´¢ã‚¯ã‚¨ãƒª | ã‚¯ãƒªãƒƒã‚¯ | è¡¨ç¤ºå›æ•° | CTR | æ²è¼‰é †ä½ |")
    report.append("|-----------|---------|---------|-----|---------|")

    for _, row in top_queries.iterrows():
        query = row["query"][:40]
        clicks = int(row["clicks"])
        impressions = int(row["impressions"])
        ctr = row["ctr"] * 100
        position = row["position"]

        report.append(
            f"| {query} | {clicks:,} | {impressions:,} | {ctr:.2f}% | {position:.1f} |"
        )

    return "\n".join(report)

def analyze_improvement_opportunities(gsc_df):
    """æ”¹å–„æ©Ÿä¼šåˆ†æ"""
    print("\nğŸ’¡ æ”¹å–„æ©Ÿä¼šåˆ†æ")

    # ã‚¯ã‚¨ãƒªåˆ¥é›†è¨ˆ
    queries = gsc_df.groupby("query").agg({
        "clicks": "sum",
        "impressions": "sum",
        "ctr": "mean",
        "position": "mean",
    }).reset_index()

    # æ”¹å–„æ©Ÿä¼š: è¡¨ç¤ºå›æ•°ã¯å¤šã„ãŒCTRãŒä½ã„ï¼ˆ5%æœªæº€ï¼‰
    low_ctr = queries[
        (queries["impressions"] >= 100) &
        (queries["ctr"] < 0.05)
    ].nlargest(10, "impressions")

    # æ”¹å–„æ©Ÿä¼š: æ²è¼‰é †ä½ãŒ4-10ä½ï¼ˆ1ãƒšãƒ¼ã‚¸ç›®ã ãŒä¸Šä½ã§ã¯ãªã„ï¼‰
    near_top = queries[
        (queries["position"] >= 4) &
        (queries["position"] <= 10) &
        (queries["impressions"] >= 50)
    ].nlargest(10, "impressions")

    report = []

    # CTRæ”¹å–„æ©Ÿä¼š
    report.append("\n### CTRæ”¹å–„æ©Ÿä¼šï¼ˆè¡¨ç¤ºå›æ•°å¤šã„ãŒä½CTRï¼‰\n")
    report.append("| æ¤œç´¢ã‚¯ã‚¨ãƒª | è¡¨ç¤ºå›æ•° | CTR | æ²è¼‰é †ä½ | æ”¹å–„ææ¡ˆ |")
    report.append("|-----------|---------|-----|---------|---------|")

    for _, row in low_ctr.iterrows():
        query = row["query"][:35]
        impressions = int(row["impressions"])
        ctr = row["ctr"] * 100
        position = row["position"]

        suggestion = "ã‚¿ã‚¤ãƒˆãƒ«ãƒ»èª¬æ˜æ–‡ã®è¦‹ç›´ã—"
        if position > 5:
            suggestion = "æ²è¼‰é †ä½æ”¹å–„ãŒå„ªå…ˆ"

        report.append(
            f"| {query} | {impressions:,} | {ctr:.2f}% | {position:.1f} | {suggestion} |"
        )

    # æ²è¼‰é †ä½æ”¹å–„æ©Ÿä¼š
    report.append("\n### æ²è¼‰é †ä½æ”¹å–„æ©Ÿä¼šï¼ˆ4-10ä½ã§è¡¨ç¤ºå›æ•°å¤šã„ï¼‰\n")
    report.append("| æ¤œç´¢ã‚¯ã‚¨ãƒª | è¡¨ç¤ºå›æ•° | æ²è¼‰é †ä½ | CTR | æ”¹å–„ææ¡ˆ |")
    report.append("|-----------|---------|---------|-----|---------|")

    for _, row in near_top.iterrows():
        query = row["query"][:35]
        impressions = int(row["impressions"])
        position = row["position"]
        ctr = row["ctr"] * 100

        report.append(
            f"| {query} | {impressions:,} | {position:.1f} | {ctr:.2f}% | å†…éƒ¨ãƒªãƒ³ã‚¯ãƒ»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å¼·åŒ– |"
        )

    return "\n".join(report)

def generate_summary(gsc_df, ga4_df):
    """ã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
    print("\nğŸ“ˆ ã‚µãƒãƒªãƒ¼ç”Ÿæˆ")

    # GSCé›†è¨ˆ
    total_clicks = gsc_df["clicks"].sum()
    total_impressions = gsc_df["impressions"].sum()
    avg_ctr = gsc_df["ctr"].mean()
    avg_position = gsc_df["position"].mean()

    # GA4é›†è¨ˆ
    total_sessions = ga4_df["sessions"].sum()
    total_users = ga4_df["totalUsers"].sum()
    avg_engagement = ga4_df["engagementRate"].mean()

    summary = f"""
## SEOãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼ï¼ˆéå»30æ—¥é–“ï¼‰

### å…¨ä½“æŒ‡æ¨™

**Search Console**
- ç·ã‚¯ãƒªãƒƒã‚¯æ•°: {total_clicks:,}
- ç·è¡¨ç¤ºå›æ•°: {total_impressions:,}
- å¹³å‡CTR: {avg_ctr*100:.2f}%
- å¹³å‡æ²è¼‰é †ä½: {avg_position:.1f}

**Google Analytics 4**
- ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {total_sessions:,}
- ç·ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {total_users:,}
- å¹³å‡ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡: {avg_engagement*100:.2f}%
"""

    return summary

    return summary

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='SEO Performance Analysis')
    parser.add_argument('--gsc-data', default='data/gsc_last30d.csv', help='Path to GSC data CSV')
    parser.add_argument('--ga4-data', default='data/ga4_last30d.csv', help='Path to GA4 data CSV')
    parser.add_argument('--output', default=None, help='Path to output report file')
    
    args = parser.parse_args()

    print("ğŸ“Š SEOãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æé–‹å§‹")

    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
    if not os.path.exists(args.gsc_data):
        # æ‹¡å¼µå­ãŒé•ã†å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§jsonæŒ‡å®šã•ã‚Œã¦ã„ã‚‹ãŒå®Ÿæ…‹ã¯csvã®å ´åˆãªã©ï¼‰
        base, _ = os.path.splitext(args.gsc_data)
        if os.path.exists(base + ".csv"):
            args.gsc_data = base + ".csv"
        else:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {args.gsc_data} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            sys.exit(1)

    if not os.path.exists(args.ga4_data):
         print(f"âŒ ã‚¨ãƒ©ãƒ¼: {args.ga4_data} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
         sys.exit(1)

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print(f"ğŸ“¥ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­... ({args.gsc_data}, {args.ga4_data})")
    try:
        gsc_df = pd.read_csv(args.gsc_data)
        ga4_df = pd.read_csv(args.ga4_data)
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)

    print(f"   GSCãƒ‡ãƒ¼ã‚¿: {len(gsc_df):,}è¡Œ")
    print(f"   GA4ãƒ‡ãƒ¼ã‚¿: {len(ga4_df):,}è¡Œ")

    # åˆ†æå®Ÿè¡Œ
    summary = generate_summary(gsc_df, ga4_df)
    top_pages = analyze_top_pages(gsc_df, ga4_df)
    queries = analyze_queries(gsc_df)
    improvements = analyze_improvement_opportunities(gsc_df)

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report_date = date.today().isoformat()
    report = f"""# SEOãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ

**ç”Ÿæˆæ—¥æ™‚**: {report_date}

{summary}

{top_pages}

{queries}

{improvements}

---

ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)
"""

    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    if args.output:
        output_file = args.output
    else:
        output_file = f"data/seo_report_{report_date}.md"
        
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(report)

    print(f"\nâœ… ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {output_file}")

if __name__ == "__main__":
    main()
